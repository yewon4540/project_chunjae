{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Hannanum, Komoran, Okt, Mecab\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from memory_profiler) (5.9.0)\n",
      "Installing collected packages: memory_profiler\n",
      "Successfully installed memory_profiler-0.61.0\n"
     ]
    }
   ],
   "source": [
    "!pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kkma = Kkma()\n",
    "okt = Okt()\n",
    "Komoran = Komoran()\n",
    "hannanum = Hannanum()\n",
    "mecab = Mecab()\n",
    "# Khaiii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소분석기\n",
    "\n",
    "## 1. 비교 대상\n",
    "- Kkma\n",
    "- Okt\n",
    "- Komoran\n",
    "- Hannanum\n",
    "- Mecab\n",
    "\n",
    "## 2. 비교 주제\n",
    "\n",
    "### (1) 시간\n",
    "- 로딩 시간\n",
    "\n",
    "### (2) 분석 범주\n",
    "- 자소구분 여부\n",
    "- 형태소 분석 정확도\n",
    "\n",
    "### (3) 띄어쓰기 구분\n",
    "- 띄어쓰기 구분 성능\n",
    "\n",
    "### (4) 동일의미어 구분\n",
    "- 동일한 의미를 가진 단어 구분 여부\n",
    "- 오탈자 구분\n",
    "\n",
    "### (5) 필요 환경\n",
    "- Java\n",
    "- numpy\n",
    "\n",
    "### (6) 메모리 활용\n",
    "- 메모리 과부화 여부\n",
    "\n",
    "### (7) 미등록어 처리\n",
    "- 미등록어 처리 성능\n",
    "- 사전 추가 기능\n",
    "\n",
    "## 3. 비교 정리\n",
    "\n",
    "## 4. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 비교 주제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_test(tagger, text):\n",
    "    time_sum = 0\n",
    "\n",
    "    for sentence in tqdm(text):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            tagger.pos(sentence)\n",
    "        except:\n",
    "            pass\n",
    "        end = time.time()\n",
    "\n",
    "        time_sum = end - start\n",
    "    \n",
    "    return time_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_check = df[:100]\n",
    "\n",
    "texts = time_check['contents'][:]\n",
    "time_list = []\n",
    "\n",
    "for tagger in [Kkma, okt, Komoran, hannanum, mecab]:\n",
    "    time_list.append(time_test(tagger, texts))\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "tagger = [Kkma, okt, Komoran, hannanum, mecab]:\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(tagger, time_list, color='g')\n",
    "plt.title('tag time for 100 data')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel('total time(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (2) 분석 범주\n",
    "- 자소구분 여부\n",
    "- 형태소 분석 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = df['keyword_dict'][0]['밀크']\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    test_sentence = sent_list[i]\n",
    "    print(f'text{i} : ', test_sentence, '\\n')\n",
    "\n",
    "    for tagger in [Kkma, okt, Komoran, hannanum, mecab]:\n",
    "        print(f'{tagger} 형태소 분석기(noun) : ', tagger.noun(test_sentence), '\\n')\n",
    "        \n",
    "\n",
    "    print('\\n----------------------\\n')\n",
    "    \n",
    "    for tagger in [Kkma, okt, Komoran, hannanum, mecab]:\n",
    "        print(f'{tagger} 형태소 분석기(pos) : ', tagger.pos(test_sentence), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자소 구분\n",
    "option1 = []\n",
    "\n",
    "# 형태소 구분 방식\n",
    "option2 = []\n",
    "\n",
    "###############################\n",
    "## 작성\n",
    "\n",
    "\n",
    "nlpy_df = pd.DataFrame({'자소 구분' : option1, '형태소 구분 방식' : option2})\n",
    "nlpy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (3) 띄어쓰기 구분\n",
    "- 띄어쓰기 구분 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option3 = []\n",
    "\n",
    "\n",
    "nlpy_df['띄어쓰기'] = option3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (4) 동일의미어 구분\n",
    "- 동일한 의미를 가진 단어 구분 여부\n",
    "- 오탈자 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_Kkma = []\n",
    "noun_okt = []\n",
    "noun_Komoran = []\n",
    "noun_hannanum = []\n",
    "noun_mecab = []\n",
    "\n",
    "for text in df['contents']:\n",
    "    \n",
    "    noun_Kkma.append(Kkma.nouns(text))\n",
    "    Kkma_memory = f\"{memory_usage()[0]:.2f} MiB\"\n",
    "\n",
    "    noun_okt.append(okt.nouns(text))\n",
    "    okt_memory = f\"{memory_usage()[0]:.2f} MiB\"\n",
    "\n",
    "    noun_Komoran.append(Komoran.nouns(text))\n",
    "    Komoran_memory = f\"{memory_usage()[0]:.2f} MiB\"\n",
    "\n",
    "    noun_hannanum.append(hannanum.nouns(text))\n",
    "    hannanum_memory = f\"{memory_usage()[0]:.2f} MiB\"\n",
    "\n",
    "    noun_mecab.append(mecab.nouns(text))\n",
    "    mecab_memory = f\"{memory_usage()[0]:.2f} MiB\"\n",
    "\n",
    "\n",
    "Kkma_nouns_counter = Counter(noun_Kkma)\n",
    "noun_Kkma_top = dict(Kkma_nouns_counter.most_common(100))\n",
    "\n",
    "okt_nouns_counter = Counter(noun_okt)\n",
    "noun_okt_top = dict(okt_nouns_counter.most_common(100))\n",
    "\n",
    "Komoran_nouns_counter = Counter(noun_Komoran)\n",
    "noun_Komoran_top = dict(Komoran_nouns_counter.most_common(100))\n",
    "\n",
    "hannanum_nouns_counter = Counter(noun_hannanum)\n",
    "noun_hannanum_top = dict(hannanum_nouns_counter.most_common(100))\n",
    "\n",
    "mecab_nouns_counter = Counter(noun_mecab)\n",
    "noun_mecab_top = dict(mecab_nouns_counter.most_common(100))\n",
    "\n",
    "print(noun_Kkma_top)\n",
    "print(noun_okt_top)\n",
    "print(noun_Komoran_top)\n",
    "print(noun_hannanum_top)\n",
    "print(noun_mecab_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (5) 필요 환경?!?!?!(미완)\n",
    "- Java Path 필요\n",
    "    - Komoran\n",
    "    - Mecab\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (6) 메모리 활용\n",
    "- 메모리 과부화 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_dict = {'Kkma' : Kkma_memory, 'okt' : okt_memory, 'Komoran' : Komoran_memory, 'hannanum' : hannanum_memory, 'mecab' : mecab_memory}\n",
    "\n",
    "for i in range(len(memory_dict)):\n",
    "    key = memory_dict.keys()[i]\n",
    "    value = memory_dict.get(key)\n",
    "    print(f'{key} 메모리 사용량 : ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (7) 미등록어 처리\n",
    "- 미등록어 처리 성능\n",
    "- 사전 추가 기능\n",
    "    - Mecab은 미등록어 발생 시 사전 추가 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미등록 언어 구별자 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kkma.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Komoran.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hannanum.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab.tagset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미등록 언어 개수 및 종류 파악하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_Kkma = []\n",
    "pos_okt = []\n",
    "pos_Komoran = []\n",
    "pos_hannanum = []\n",
    "pos_mecab = []\n",
    "\n",
    "for text in tqdm(df['contents']):\n",
    "    pos_Kkma.append(Kkma.pos(text))\n",
    "\n",
    "for text in tqdm(df['contents']):\n",
    "    pos_okt.append(okt.pos(text))\n",
    "\n",
    "for text in tqdm(df['contents']):\n",
    "    pos_Komoran.append(Komoran.pos(text))\n",
    "\n",
    "for text in tqdm(df['contents']):\n",
    "    pos_hannanum.append(hannanum.pos(text))\n",
    "\n",
    "for text in tqdm(df['contents']):\n",
    "    pos_mecab.append(mecab.pos(text))\n",
    "\n",
    "# 미등록 언어 찾기\n",
    "non_Kkma = []\n",
    "non_okt = []\n",
    "non_Komoran = []\n",
    "non_hannanum = []\n",
    "non_mecab = []\n",
    "\n",
    "for i in pos_Kkma:\n",
    "    if i[1] == ???:\n",
    "        non_Kkma.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in pos_okt:\n",
    "    if i[1] == ???:\n",
    "        non_okt.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in pos_Komoran:\n",
    "    if i[1] == ???:\n",
    "        non_Komoran.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in pos_hannanum:\n",
    "    if i[1] == ???:\n",
    "        non_hannanum.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in pos_mecab:\n",
    "    if i[1] == ???:\n",
    "        non_mecab.append(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght_list = []\n",
    "non_tagger_list = [non_Kkma, non_okt, non_Komoran, non_hannanum, non_mecab]:\n",
    "\n",
    "for i in non_tagger_list:\n",
    "    lenght_list.append(len(i))\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(non_tagger_list, lenght_list, color='b')\n",
    "plt.title('tag unregistered language')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 비교정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 결론 : \n",
    "\n",
    "- 어쩌구저쩌구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
